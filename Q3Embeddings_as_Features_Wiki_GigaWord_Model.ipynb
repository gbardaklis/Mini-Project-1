{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbardaklis/Mini-Project-1/blob/main/Q3Embeddings_as_Features_Wiki_GigaWord_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn60bpNT6Tkt",
        "outputId": "64d1fc64-5180-4d80-f33a-823530c85dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Needed Imports\n",
        "import gensim.downloader as api\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBjvWkFjC5kl"
      },
      "outputs": [],
      "source": [
        "# More imports\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJAgKDCuC-eZ"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/goemotions.json\") as f:\n",
        "    # data2 = json.loads(f.read())\n",
        "    data = json.load(f)\n",
        "\n",
        "# importing the json file into a dataframe \n",
        "df = pd.DataFrame(data, columns = ['Post', 'Emotion', 'Sentiment'])\n",
        "postsDict = df['Post'].values.tolist()\n",
        "# postsDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3Sy-LqBLOPg"
      },
      "outputs": [],
      "source": [
        "emotionDict = df['Emotion'].values.tolist()\n",
        "# emotionDict\n",
        "sentimentDict = df['Sentiment'].values.tolist()\n",
        "# sentimentDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays a List of Pretrained Models avail on gensim\n",
        "print(list(api.info()['models'].keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsLaQ_eYEtC",
        "outputId": "ca4ad56d-d7bb-498f-b74f-416fd25c849f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdWgWu3IOCqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce594db-fe48-4007-88f0-eb8284025aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# 3.1 \n",
        "corpusNews = api.load('glove-wiki-gigaword-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyiPd7sI-x9o",
        "outputId": "e299ade5-f1b8-4e7e-9349-7eaf0a404f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of tokens is 2642128\n"
          ]
        }
      ],
      "source": [
        "# 3.2\n",
        "tokenCount = 0\n",
        "tokenPost = []\n",
        "\n",
        "for x in postsDict:\n",
        "  tokens = word_tokenize(x)\n",
        "  tokenPost.append(tokens)\n",
        "  tokenCount = tokenCount + len(tokens)\n",
        "print(f'The total number of tokens is {tokenCount}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Xcn0tU1YrA",
        "outputId": "e3227906-6eab-4dfe-a2db-b657c2cbaa92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The failed count is: 387248\n",
            "The hit rate is as follows: 85.34332931636924\n"
          ]
        }
      ],
      "source": [
        "# fail counter for punctuation and words not found in corpus \n",
        "failed = 0\n",
        "averageEmb = []\n",
        "averageEmbAll = []\n",
        "\n",
        "# Take the X TokenPost\n",
        "for index, iterator in enumerate(tokenPost):\n",
        "  for x in iterator:\n",
        "    try:\n",
        "      # Assign Corpus[x] to single word\n",
        "      singleWord = corpusNews[x]\n",
        "      # New List append that word\n",
        "      averageEmb.append(singleWord)\n",
        "    except KeyError:\n",
        "      # Doesn't fnd throw error increment counter\n",
        "      failed += 1\n",
        "  if len(averageEmb) != 0:\n",
        "    average = np.average(averageEmb, axis = 0)\n",
        "    averageEmbAll.append(average)\n",
        "    averageEmb.clear()\n",
        "  else: \n",
        "    averageEmbAll.append([0] * 300)\n",
        "# 3.3\n",
        "print(f'The failed count is: {failed}')\n",
        "\n",
        "# 3.4 \n",
        "hitRate = ((tokenCount - failed) / tokenCount) *100\n",
        "print(f'The hit rate is as follows: {hitRate}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CxkCj5fP3tR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh6eXEBogfUQ"
      },
      "outputs": [],
      "source": [
        "# splitting data 80% train 20% test\n",
        "post_train, post_test, emotion_train, emotion_test = train_test_split(averageEmbAll, emotionDict, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data 80% train 20% test\n",
        "post_train_sent, post_test_sent, sentiment_train, sentiment_test = train_test_split(averageEmbAll, sentimentDict, test_size = 0.2)"
      ],
      "metadata": {
        "id": "S8EIQS7ImYMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL6WrnaZtzcu",
        "outputId": "63f6e5a2-fe37-434f-f842-8349f039aa73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 56.9 s, sys: 22.8 s, total: 1min 19s\n",
            "Wall time: 40.8 s\n",
            "CPU times: user 1min 18s, sys: 31.8 s, total: 1min 50s\n",
            "Wall time: 57.2 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(early_stopping=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 3.5 Base-MLP with the default parameters\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(early_stopping=True)\n",
        "%time mlp.fit(post_train, emotion_train)\n",
        "%time mlp.fit(post_train, sentiment_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.7\n",
        "# Open Text Word doc for Writing to\n",
        "performanceTxt = open(\"performanceWordEmb_Wiki_GigaWord.txt\", \"w\")\n",
        "# Write to Text Word Doc the Accuracy and the Classification Report for BASE \n",
        "performanceTxt.write(f\" The following is the information for the Base MLP Classifier \\n  \" )\n",
        "performanceTxt.write(f\" This is the Accuracy of the Tests for the emotion model \\n {mlp.score(post_test, emotion_test) * 100} \\n  \" )\n",
        "performanceTxt.write(f\" This is the Accuracy of the Tests for the sentiment model \\n {mlp.score(post_test, sentiment_test) * 100} \\n  \" )\n",
        "emotion_pred = mlp.fit(post_train, emotion_train).predict(post_test)\n",
        "performanceTxt.write(f\" This is the Classification Report for the emotion model \\n {metrics.classification_report(emotion_test, emotion_pred,labels=np.unique(emotion_test), zero_division=0)} \\n  \" )\n",
        "sentiment_pred = mlp.fit(post_train, sentiment_train).predict(post_test)\n",
        "performanceTxt.write(f\" This is the Classification Report for the sentiment model \\n {metrics.classification_report(sentiment_test, sentiment_pred,labels=np.unique(sentiment_test), zero_division=0)} \\n  \" )\n",
        "print(\"Wrote everything to the file good job!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQIZEtRPB5Av",
        "outputId": "dfa5388b-0f3c-41cb-ff33-58eba6ab40bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote everything to the file good job!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}