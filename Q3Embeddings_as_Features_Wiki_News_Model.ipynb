{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbardaklis/Mini-Project-1/blob/main/Q3Embeddings_as_Features_Wiki_News_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn60bpNT6Tkt",
        "outputId": "a009326a-529b-43f5-b8f4-a7aaab13f2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Needed Imports\n",
        "import gensim.downloader as api\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uBjvWkFjC5kl"
      },
      "outputs": [],
      "source": [
        "# More imports\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aJAgKDCuC-eZ"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/goemotions.json\") as f:\n",
        "    # data2 = json.loads(f.read())\n",
        "    data = json.load(f)\n",
        "\n",
        "# importing the json file into a dataframe \n",
        "df = pd.DataFrame(data, columns = ['Post', 'Emotion', 'Sentiment'])\n",
        "postsDict = df['Post'].values.tolist()\n",
        "# postsDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j3Sy-LqBLOPg"
      },
      "outputs": [],
      "source": [
        "emotionDict = df['Emotion'].values.tolist()\n",
        "# emotionDict\n",
        "sentimentDict = df['Sentiment'].values.tolist()\n",
        "# sentimentDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays a List of Pretrained Models avail on gensim\n",
        "print(list(api.info()['models'].keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsLaQ_eYEtC",
        "outputId": "c9cb3d42-f660-434b-c713-171b8bb98d8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vdWgWu3IOCqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa616809-ec1f-4db2-b223-5c31febff253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 98.5% 944.4/958.4MB downloaded"
          ]
        }
      ],
      "source": [
        "# 3.1 \n",
        "corpusNews = api.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyiPd7sI-x9o",
        "outputId": "e2d25116-696c-4191-c738-9b6d36002b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of tokens is 2642128\n"
          ]
        }
      ],
      "source": [
        "# 3.2\n",
        "tokenCount = 0\n",
        "tokenPost = []\n",
        "\n",
        "for x in postsDict:\n",
        "  tokens = word_tokenize(x)\n",
        "  tokenPost.append(tokens)\n",
        "  tokenCount = tokenCount + len(tokens)\n",
        "print(f'The total number of tokens is {tokenCount}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Xcn0tU1YrA",
        "outputId": "2a7217b5-b3da-436b-fb3d-7a1c8f51421a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The failed count is: 51843\n",
            "The hit rate is as follows: 98.03783162662823\n"
          ]
        }
      ],
      "source": [
        "# fail counter for punctuation and words not found in corpus \n",
        "failed = 0\n",
        "averageEmb = []\n",
        "averageEmbAll = []\n",
        "\n",
        "# Take the X TokenPost\n",
        "for index, iterator in enumerate(tokenPost):\n",
        "  for x in iterator:\n",
        "    try:\n",
        "      # Assign Corpus[x] to single word\n",
        "      singleWord = corpusNews[x]\n",
        "      # New List append that word\n",
        "      averageEmb.append(singleWord)\n",
        "    except KeyError:\n",
        "      # Doesn't fnd throw error increment counter\n",
        "      failed += 1\n",
        "  if len(averageEmb) != 0:\n",
        "    average = np.average(averageEmb, axis = 0)\n",
        "    averageEmbAll.append(average)\n",
        "    averageEmb.clear()\n",
        "  else: \n",
        "    # Set the vector to 0 \n",
        "    averageEmbAll.append([0] * 300)\n",
        "# 3.3\n",
        "print(f'The failed count is: {failed}')\n",
        "\n",
        "# 3.4 \n",
        "hitRate = ((tokenCount - failed) / tokenCount) *100\n",
        "print(f'The hit rate is as follows: {hitRate}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CxkCj5fP3tR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh6eXEBogfUQ"
      },
      "outputs": [],
      "source": [
        "# splitting data 80% train 20% test\n",
        "post_train, post_test, emotion_train, emotion_test = train_test_split(averageEmbAll, emotionDict, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data 80% train 20% test\n",
        "post_train_sent, post_test_sent, sentiment_train, sentiment_test = train_test_split(averageEmbAll, sentimentDict, test_size = 0.2)"
      ],
      "metadata": {
        "id": "S8EIQS7ImYMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL6WrnaZtzcu",
        "outputId": "5d131f39-a9f1-4771-eb5e-59469617b678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14min 9s, sys: 5min 29s, total: 19min 39s\n",
            "Wall time: 10min 15s\n",
            "CPU times: user 4min 32s, sys: 2min 5s, total: 6min 37s\n",
            "Wall time: 3min 28s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(early_stopping=True)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# 3.5 Base-MLP with the default parameters\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(early_stopping=True)\n",
        "%time mlp.fit(post_train, emotion_train)\n",
        "%time mlp.fit(post_train, sentiment_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.7\n",
        "# Open Text Word doc for Writing to\n",
        "performanceTxt2 = open(\"performanceWordEmb_Wiki_News2.txt\", \"w\")\n",
        "# Write to Text Word Doc the Accuracy and the Classification Report for BASE \n",
        "performanceTxt2.write(f\" The following is the information for the Base MLP Classifier \\n  \" )\n",
        "performanceTxt2.write(f\" This is the Accuracy of the Tests for the emotion model \\n {mlp.score(post_test, emotion_test) * 100} \\n  \" )\n",
        "performanceTxt2.write(f\" This is the Accuracy of the Tests for the sentiment model \\n {mlp.score(post_test, sentiment_test) * 100} \\n  \" )\n",
        "emotion_pred = mlp.fit(post_train, emotion_train).predict(post_test)\n",
        "performanceTxt2.write(f\" This is the Classification Report for the emotion model \\n {metrics.classification_report(emotion_test, emotion_pred,labels=np.unique(emotion_test), zero_division=0)} \\n  \" )\n",
        "sentiment_pred = mlp.fit(post_train_sent, sentiment_train).predict(post_test_sent)\n",
        "performanceTxt2.write(f\" This is the Classification Report for the sentiment model \\n {metrics.classification_report(sentiment_test, sentiment_pred,labels=np.unique(sentiment_test), zero_division=0)} \\n  \" )\n",
        "print(\"Wrote everything to the file good job!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQIZEtRPB5Av",
        "outputId": "226d4079-c211-47f6-8982-5a635f73138c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote everything to the file good job!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}